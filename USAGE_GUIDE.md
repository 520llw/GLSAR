### 4. è¿è¡Œå®Œæ•´æ€§æ£€æŸ¥
```bash
python check_modules.py
```

è¿™ä¼šæ£€æŸ¥ï¼š
- âœ… PyTorchå®‰è£…
- âœ… æ‰€æœ‰ä¾èµ–åŒ…
- âœ… é…ç½®æ–‡ä»¶
- âœ… æ¨¡å‹æ–‡ä»¶
- âœ… æ•°æ®æ–‡ä»¶
- âœ… è®­ç»ƒè„šæœ¬

### 5. å‡†å¤‡æ•°æ®
```bash
# å°†ä½ çš„æ•°æ®æ”¾åˆ°å¯¹åº”ç›®å½•
# å›¾åƒæ ¼å¼: .jpg, .png
# æ ‡ç­¾æ ¼å¼: YOLOæ ¼å¼ (.txt)

# æ£€æŸ¥æ•°æ®
python -c "
from pathlib import Path
train_imgs = list(Path('data/train/images').glob('*'))
train_labels = list(Path('data/train/labels').glob('*'))
print(f'Train images: {len(train_imgs)}')
print(f'Train labels: {len(train_labels)}')
"
```

### 6. æµ‹è¯•æ¨¡å‹
```bash
# å¿«é€Ÿæµ‹è¯•
python test_model.py

# å¦‚æœæˆåŠŸï¼Œä½ ä¼šçœ‹åˆ°ï¼š
# âœ… All tests passed!
```

### 7. å¼€å§‹è®­ç»ƒ
```bash
# å®Œæ•´å¢å¼ºç‰ˆæœ¬
python train_enhanced.py

# æˆ–é€‰æ‹©ç‰¹å®šé…ç½®
python train_enhanced.py --no_frequency  # ä»…attention
python train_enhanced.py --baseline      # åŸºçº¿ç‰ˆæœ¬
```

---

## ğŸ”§ æ•…éšœæ’é™¤é€ŸæŸ¥è¡¨

| é—®é¢˜ | å¯èƒ½åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|----------|----------|
| ModuleNotFoundError: models.utils.attention | æ–‡ä»¶ç¼ºå¤± | åˆ›å»º `models/utils/attention.py` |
| CUDA out of memory | æ˜¾å­˜ä¸è¶³ | `--batch_size 4` æˆ– `--no_frequency` |
| Loss is NaN | å­¦ä¹ ç‡è¿‡å¤§ | é™ä½å­¦ä¹ ç‡åˆ° `5e-5` |
| No improvement | æ•°æ®é—®é¢˜ | æ£€æŸ¥æ ‡ç­¾æ ¼å¼å’Œæ•°æ®è´¨é‡ |
| Import error | è·¯å¾„é—®é¢˜ | ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ |
| Gradient explosion | æ¢¯åº¦è£å‰ªä¸å¤Ÿ | è®¾ç½® `GRAD_CLIP_MAX_NORM = 5.0` |

---

## ğŸ“š ä»£ç ç»„ç»‡æœ€ä½³å®è·µ

### 1. æ¨¡å—åŒ–è®¾è®¡
```python
# å¥½çš„åšæ³• âœ…
from models.utils.attention import CBAM
from models.utils.frequency import SARFrequencyAttention

class MyModel(nn.Module):
    def __init__(self):
        self.cbam = CBAM(256)
        self.freq_att = SARFrequencyAttention(256)

# ä¸å¥½çš„åšæ³• âŒ
# æŠŠæ‰€æœ‰ä»£ç å†™åœ¨ä¸€ä¸ªæ–‡ä»¶é‡Œ
```

### 2. é…ç½®ç®¡ç†
```python
# å¥½çš„åšæ³• âœ…
from config.sar_ship_config import cfg

model = EnhancedDenoDet().to(cfg.DEVICE)
optimizer = cfg.get_optimizer(model)

# ä¸å¥½çš„åšæ³• âŒ
# ç¡¬ç¼–ç å‚æ•°
model = EnhancedDenoDet().to('cuda')
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)
```

### 3. å®éªŒç®¡ç†
```bash
# å¥½çš„åšæ³• âœ…
# ä½¿ç”¨æœ‰æ„ä¹‰çš„å®éªŒåç§°
python train_enhanced.py --exp_name resnet50_cbam_freq_lr1e4

# ä¸å¥½çš„åšæ³• âŒ
python train_enhanced.py  # ä½¿ç”¨éšæœºç”Ÿæˆçš„åç§°
```

---

## ğŸ¯ å¿«é€Ÿå¼€å§‹æ¸…å•

### â˜‘ï¸ ç¬¬ä¸€æ¬¡ä½¿ç”¨

- [ ] 1. è¿è¡Œ `python check_modules.py` æ£€æŸ¥ç¯å¢ƒ
- [ ] 2. åˆ›å»º `models/utils/attention.py` å’Œ `frequency.py`
- [ ] 3. ç¡®ä¿æ•°æ®ç›®å½•ç»“æ„æ­£ç¡®
- [ ] 4. è¿è¡Œ `python test_model.py --test data` æµ‹è¯•æ•°æ®åŠ è½½
- [ ] 5. è¿è¡Œ `python test_model.py` å®Œæ•´æµ‹è¯•
- [ ] 6. å¼€å§‹è®­ç»ƒ `python train_enhanced.py`

### â˜‘ï¸ æ¯æ¬¡è®­ç»ƒå‰

- [ ] 1. æ£€æŸ¥æ•°æ®è·¯å¾„åœ¨ `config/sar_ship_config.py` ä¸­æ­£ç¡®
- [ ] 2. ç¡®è®¤ batch size å’Œå­¦ä¹ ç‡åˆé€‚
- [ ] 3. é€‰æ‹©åˆé€‚çš„å¢å¼ºæ¨¡å—é…ç½®
- [ ] 4. è®¾ç½®æœ‰æ„ä¹‰çš„å®éªŒåç§°
- [ ] 5. ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´ä¿å­˜checkpoint

### â˜‘ï¸ è®­ç»ƒè¿‡ç¨‹ä¸­

- [ ] 1. ç›‘æ§è®­ç»ƒæ›²çº¿ï¼ˆæ¯5ä¸ªepochæŸ¥çœ‹ä¸€æ¬¡ï¼‰
- [ ] 2. æ£€æŸ¥lossæ˜¯å¦æ­£å¸¸ä¸‹é™
- [ ] 3. è§‚å¯Ÿå­¦ä¹ ç‡è°ƒåº¦æ˜¯å¦åˆç†
- [ ] 4. æ³¨æ„æ˜¯å¦æœ‰OOMé”™è¯¯
- [ ] 5. å®šæœŸæŸ¥çœ‹éªŒè¯é›†æ€§èƒ½

### â˜‘ï¸ è®­ç»ƒå®Œæˆå

- [ ] 1. è¿è¡Œ `python tools/visualize.py` æŸ¥çœ‹é¢„æµ‹
- [ ] 2. åˆ†æè®­ç»ƒæ›²çº¿æ‰¾å‡ºé—®é¢˜
- [ ] 3. å¯¹æ¯”ä¸åŒé…ç½®çš„æ€§èƒ½
- [ ] 4. ä¿å­˜æœ€ä½³æ¨¡å‹å’Œé…ç½®
- [ ] 5. è®°å½•å®éªŒç»“æœ

---

## ğŸ’» å‘½ä»¤é€ŸæŸ¥è¡¨

```bash
# ============ æµ‹è¯•ç›¸å…³ ============
# å®Œæ•´æµ‹è¯•
python test_model.py

# å•é¡¹æµ‹è¯•
python test_model.py --test data      # æµ‹è¯•æ•°æ®
python test_model.py --test forward   # æµ‹è¯•å‰å‘ä¼ æ’­
python test_model.py --test modules   # æµ‹è¯•æ¨¡å—
python test_model.py --test optimizer # æµ‹è¯•ä¼˜åŒ–å™¨

# æ£€æŸ¥ç¯å¢ƒ
python check_modules.py


# ============ è®­ç»ƒç›¸å…³ ============
# å®Œæ•´å¢å¼ºè®­ç»ƒ
python train_enhanced.py

# Baselineè®­ç»ƒ
python train_enhanced.py --baseline

# éƒ¨åˆ†å¢å¼º
python train_enhanced.py --no_frequency
python train_enhanced.py --no_attention
python train_enhanced.py --no_diff_lr

# è‡ªå®šä¹‰å‚æ•°
python train_enhanced.py \
  --epochs 100 \
  --batch_size 16 \
  --exp_name my_exp

# æ–­ç‚¹ç»­è®­
python train_enhanced.py --resume latest
python train_enhanced.py --resume checkpoints/checkpoint_epoch_50.pth


# ============ å¯è§†åŒ–ç›¸å…³ ============
# åŸºç¡€å¯è§†åŒ–
python tools/visualize.py --checkpoint checkpoints/best_model.pth

# å®Œæ•´å¯è§†åŒ–
python tools/visualize.py \
  --checkpoint checkpoints/best_model.pth \
  --num_samples 50 \
  --conf_threshold 0.5 \
  --show_gt \
  --save_crops


# ============ è°ƒè¯•ç›¸å…³ ============
# æ‰“å°æ¨¡å‹ç»“æ„
python -c "
from models.detectors.denodet import EnhancedDenoDet
model = EnhancedDenoDet()
print(model)
"

# ç»Ÿè®¡å‚æ•°é‡
python -c "
from models.detectors.denodet import EnhancedDenoDet
model = EnhancedDenoDet()
total = sum(p.numel() for p in model.parameters())
print(f'Total parameters: {total:,}')
"

# æ£€æŸ¥æ•°æ®
python -c "
from data.loaders import get_train_dataloader
loader = get_train_dataloader()
batch = next(iter(loader))
print('Batch keys:', batch.keys())
print('Image shape:', batch['img'].shape)
print('GT boxes:', [len(b) for b in batch['gt_bboxes']])
"
```

---

## ğŸ“ è¿›é˜¶æŠ€å·§

### 1. å­¦ä¹ ç‡æŸ¥æ‰¾å™¨
```python
# åˆ›å»º tools/find_lr.py
import torch
from torch.cuda.amp import autocast
import matplotlib.pyplot as plt

def find_lr(model, train_loader, init_lr=1e-8, final_lr=10, beta=0.98):
    """Learning rate range test"""
    num_batches = len(train_loader)
    mult = (final_lr / init_lr) ** (1/num_batches)
    lr = init_lr
    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)
    
    avg_loss = 0
    best_loss = 0
    losses = []
    lrs = []
    
    for batch_idx, data in enumerate(train_loader):
        # Forward
        loss = model(data)['total_loss']
        
        # Smooth loss
        avg_loss = beta * avg_loss + (1-beta) * loss.item()
        smoothed_loss = avg_loss / (1 - beta**(batch_idx+1))
        
        # Record
        losses.append(smoothed_loss)
        lrs.append(lr)
        
        # Stop if loss explodes
        if batch_idx > 0 and smoothed_loss > 4 * best_loss:
            break
        
        if smoothed_loss < best_loss or batch_idx == 0:
            best_loss = smoothed_loss
        
        # Backward
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
        
        # Update LR
        lr *= mult
        for param_group in optimizer.param_groups:
            param_group['lr'] = lr
    
    # Plot
    plt.figure(figsize=(10, 6))
    plt.plot(lrs, losses)
    plt.xscale('log')
    plt.xlabel('Learning Rate')
    plt.ylabel('Loss')
    plt.title('Learning Rate Finder')
    plt.grid(True)
    plt.savefig('lr_finder.png')
    print(f"Suggested LR: {lrs[losses.index(min(losses))]:.2e}")
```

### 2. æ¢¯### 2. æ‰“å°æ¨¡å‹ç»“æ„
```python
# åœ¨è®­ç»ƒå‰æ·»åŠ 
from torchsummary import summary
summary(model, input_size=(1, 512, 512))
```

### 3. ç›‘æ§æ¢¯åº¦
```python
# åœ¨ engine/trainer.py çš„ train_epoch ä¸­æ·»åŠ 
for name, param in self.model.named_parameters():
    if param.grad is not None:
        grad_norm = param.grad.norm().item()
        if grad_norm > 100:
            print(f"Large gradient: {name} = {grad_norm:.2f}")
```

### 4. å¯è§†åŒ–ç‰¹å¾å›¾
```python
# åˆ›å»º tools/visualize_features.py
import torch
import matplotlib.pyplot as plt

def visualize_feature_maps(model, img, layer_name):
    """å¯è§†åŒ–ä¸­é—´å±‚ç‰¹å¾å›¾"""
    features = {}
    
    def hook(module, input, output):
        features['output'] = output
    
    # æ³¨å†Œhook
    handle = getattr(model, layer_name).register_forward_hook(hook)
    
    # Forward
    with torch.no_grad():
        model(img)
    
    # å¯è§†åŒ–
    feat = features['output'][0]  # [C, H, W]
    plt.figure(figsize=(20, 4))
    for i in range(min(8, feat.shape[0])):
        plt.subplot(1, 8, i+1)
        plt.imshow(feat[i].cpu(), cmap='jet')
        plt.axis('off')
    plt.show()
    
    handle.remove()
```

---

## ğŸ“¦ å®Œæ•´å®‰è£…æŒ‡å—

### 1. å…‹éš†/è®¾ç½®é¡¹ç›®
```bash
# åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir sar_ship_detection
cd sar_ship_detection

# åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„
mkdir -p config models/{detectors,backbones,necks,heads,utils,losses}
mkdir -p data/{train,val}/{images,labels}
mkdir -p engine tools checkpoints logs
```

### 2. å®‰è£…ä¾èµ–
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
conda create -n sar_detection python=3.8
conda activate sar_detection

# å®‰è£…PyTorchï¼ˆæ ¹æ®CUDAç‰ˆæœ¬é€‰æ‹©ï¼‰
# CUDA 11.8
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# æˆ– CUDA 12.1
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# æˆ– CPU only
pip install torch torchvision

# å®‰è£…å…¶ä»–ä¾èµ–
pip install opencv-python numpy matplotlib tqdm
```

### 3. å¤åˆ¶ä»£ç æ–‡ä»¶
å°†ä»¥ä¸‹æ–‡ä»¶å¤åˆ¶åˆ°å¯¹åº”ä½ç½®ï¼š
- âœ… `config/sar_ship_config.py`
- âœ… `models/utils/attention.py`
- âœ… `models/utils/frequency.py`
- âœ… `train_enhanced.py`
- âœ… `test_model.py`
- âœ… `tools/visualize.py`
- âœ… `check_modules.py`

### 4. è¿è¡Œå®Œæ•´æ€§æ£€æŸ¥
```bash# SAR Ship Detection - ä½¿ç”¨æŒ‡å—

## ğŸ“‹ ç›®å½•
1. [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
2. [æµ‹è¯•æ¨¡å‹](#æµ‹è¯•æ¨¡å‹)
3. [è®­ç»ƒæ¨¡å‹](#è®­ç»ƒæ¨¡å‹)
4. [å¯è§†åŒ–é¢„æµ‹](#å¯è§†åŒ–é¢„æµ‹)
5. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸ”§ ç¯å¢ƒé…ç½®

### å¿…è¦ä¾èµ–
```bash
pip install torch torchvision
pip install opencv-python numpy matplotlib
pip install tqdm pathlib
```

### ç›®å½•ç»“æ„
```
project/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ sar_ship_config.py       # âœ… å·²ä¿®å¤
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ detectors/
â”‚   â”‚   â””â”€â”€ denodet.py           # å¢å¼ºç‰ˆæ£€æµ‹å™¨
â”‚   â”œâ”€â”€ backbones/
â”‚   â”œâ”€â”€ necks/
â”‚   â”œâ”€â”€ heads/
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ attention.py
â”‚       â””â”€â”€ frequency.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â””â”€â”€ labels/
â”‚   â””â”€â”€ val/
â”‚       â”œâ”€â”€ images/
â”‚       â””â”€â”€ labels/
â”œâ”€â”€ engine/
â”‚   â””â”€â”€ trainer.py
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ visualize.py             # âœ… å·²ä¿®å¤
â”œâ”€â”€ train_enhanced.py            # âœ… å·²ä¿®å¤
â”œâ”€â”€ test_model.py                # âœ… å·²ä¿®å¤
â””â”€â”€ checkpoints/
```

---

## ğŸ§ª æµ‹è¯•æ¨¡å‹

### 1. è¿è¡Œå®Œæ•´æµ‹è¯•
```bash
python test_model.py
```

è¿™å°†æµ‹è¯•ï¼š
- âœ… æ•°æ®åŠ è½½
- âœ… æ¨¡å‹å‰å‘ä¼ æ’­
- âœ… åå‘ä¼ æ’­
- âœ… æ¨ç†æ¨¡å¼
- âœ… å¢å¼ºæ¨¡å—
- âœ… ä¼˜åŒ–å™¨é…ç½®

### 2. è¿è¡Œå•é¡¹æµ‹è¯•
```bash
# ä»…æµ‹è¯•æ•°æ®åŠ è½½
python test_model.py --test data

# ä»…æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­
python test_model.py --test forward

# ä»…æµ‹è¯•å¢å¼ºæ¨¡å—
python test_model.py --test modules

# ä»…æµ‹è¯•ä¼˜åŒ–å™¨
python test_model.py --test optimizer
```

### é¢„æœŸè¾“å‡ºç¤ºä¾‹
```
================================================================================
ğŸš€ SAR Ship Detection - Model Testing Suite
================================================================================
Device: cuda
Batch Size: 8
Image Size: (512, 512)
================================================================================

ğŸ§ª Testing Data Loading
âœ… Batch loaded successfully
âœ… Channel check passed
âœ… Batch size check passed
âœ… Image size check passed

ğŸ§ª Testing Model Forward Pass
âœ… Model initialized with 43,234,567 parameters
âœ… Forward pass successful
âœ… Loss validity check passed
âœ… Backward pass successful
âœ… Gradient check passed
âœ… Inference successful

ğŸ“Š Test Summary
Total tests: 4
âœ… Passed: 4
âŒ Failed: 0
ğŸ‰ All tests passed successfully!
```

---

## ğŸš€ è®­ç»ƒæ¨¡å‹

### 1. åŸºç¡€è®­ç»ƒï¼ˆå®Œæ•´å¢å¼ºï¼‰
```bash
python train_enhanced.py
```

é»˜è®¤é…ç½®ï¼š
- âœ… Attentionæ¨¡å—å¯ç”¨
- âœ… Frequencyæ¨¡å—å¯ç”¨
- âœ… å·®å¼‚åŒ–å­¦ä¹ ç‡å¯ç”¨

### 2. Baselineè®­ç»ƒï¼ˆæ— å¢å¼ºï¼‰
```bash
python train_enhanced.py --baseline
```

### 3. éƒ¨åˆ†å¢å¼ºè®­ç»ƒ

#### ä»…ä½¿ç”¨Attentionæ¨¡å—
```bash
python train_enhanced.py --no_frequency
```

#### ä»…ä½¿ç”¨Frequencyæ¨¡å—
```bash
python train_enhanced.py --no_attention
```

#### ä½¿ç”¨å¢å¼ºä½†ä¸ç”¨å·®å¼‚åŒ–å­¦ä¹ ç‡
```bash
python train_enhanced.py --no_diff_lr
```

### 4. è‡ªå®šä¹‰è®­ç»ƒå‚æ•°
```bash
python train_enhanced.py \
  --epochs 50 \
  --batch_size 16 \
  --exp_name my_experiment \
  --no_val  # ç¦ç”¨éªŒè¯
```

### 5. æ–­ç‚¹ç»­è®­
```bash
# ä»æœ€æ–°checkpointç»§ç»­
python train_enhanced.py --resume latest

# ä»æŒ‡å®šcheckpointç»§ç»­
python train_enhanced.py --resume checkpoints/checkpoint_epoch_20.pth
```

### è®­ç»ƒè¾“å‡º
```
================================================================================
SAR Ship Detection Training - Enhanced Version
================================================================================
ğŸ“ Experiment: sar_att_freq_difflr_20241011_143022
ğŸ–¥ï¸  Device: cuda
ğŸ”„ Epochs: 100
ğŸ“¦ Batch Size: 8
ğŸ–¼ï¸  Image Size: (512, 512)
ğŸŒ± Seed: 42
âœ¨ Attention Modules: âœ…
ğŸ“¡ Frequency Modules: âœ…
ğŸ“ Differential LR: âœ…
================================================================================

ğŸ”§ Initializing model...
âœ… Frequency modules initialized
âœ… Attention modules initialized
âœ… Enhanced Model initialized - Total params: 43,234,567
âœ… Total parameters: 43,234,567
âœ… Trainable parameters: 43,234,567

ğŸ“¦ Loading datasets...
âœ… Train batches: 1250
âœ… Val batches: 156

ğŸ¯ Creating trainer...
ğŸ”¥ Using differential learning rates for enhanced modules

ğŸ“Š Parameter Groups:
  Group 0: 21,234,567 params, lr=1.00e-05  # Backbone
  Group 1: 5,123,456 params, lr=1.00e-04   # Attention
  Group 2: 4,876,544 params, lr=1.00e-04   # Frequency
  Group 3: 8,000,000 params, lr=1.00e-04   # Neck
  Group 4: 4,000,000 params, lr=1.00e-04   # Head
```

### è®­ç»ƒç›‘æ§

#### å®æ—¶æ—¥å¿—
```
Epoch 1/100 - train_loss: 2.3456 (cls: 1.2345, bbox: 1.1111), lr: 1.00e-04
Epoch 2/100 - train_loss: 2.1234 (cls: 1.1234, bbox: 1.0000), val_loss: 2.2345, lr: 9.80e-05
...
```

#### è®­ç»ƒæ›²çº¿
è‡ªåŠ¨ä¿å­˜åˆ°ï¼š`logs/{experiment_name}/curves/training_curves.png`

åŒ…å«4ä¸ªå­å›¾ï¼š
- ğŸ“‰ æ€»æŸå¤±ï¼ˆè®­ç»ƒ + éªŒè¯ï¼‰
- ğŸ“‰ åˆ†ç±»æŸå¤±
- ğŸ“‰ è¾¹ç•Œæ¡†æŸå¤±
- ğŸ“‰ å­¦ä¹ ç‡å˜åŒ–

#### Checkpointä¿å­˜
- `checkpoints/best_model.pth` - æœ€ä½³æ¨¡å‹
- `checkpoints/latest.pth` - æœ€æ–°æ¨¡å‹
- `checkpoints/checkpoint_epoch_N.pth` - æ¯5ä¸ªepochä¿å­˜

---

## ğŸ“Š å¯è§†åŒ–é¢„æµ‹

### 1. åŸºç¡€å¯è§†åŒ–
```bash
python tools/visualize.py --checkpoint checkpoints/best_model.pth
```

### 2. è‡ªå®šä¹‰å‚æ•°
```bash
python tools/visualize.py \
  --checkpoint checkpoints/best_model.pth \
  --num_samples 50 \
  --conf_threshold 0.5 \
  --show_gt \
  --save_crops \
  --output_dir my_visualizations
```

### å‚æ•°è¯´æ˜
- `--checkpoint`: æ¨¡å‹æƒé‡è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
- `--num_samples`: å¯è§†åŒ–æ ·æœ¬æ•°é‡ï¼ˆé»˜è®¤10ï¼‰
- `--conf_threshold`: ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆé»˜è®¤0.3ï¼‰
- `--show_gt`: æ˜¾ç¤ºground truthï¼ˆç»¿è‰²æ¡†ï¼‰
- `--save_crops`: ä¿å­˜æ£€æµ‹ç›®æ ‡çš„è£å‰ªå›¾
- `--output_dir`: è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤visualizationsï¼‰
- `--data_dir`: è‡ªå®šä¹‰æ•°æ®ç›®å½•

### è¾“å‡ºç¤ºä¾‹
```
================================================================================
SAR Ship Detection - Prediction Visualization
================================================================================
Checkpoint: checkpoints/best_model.pth
Output directory: visualizations
Confidence threshold: 0.3
Show ground truth: True
================================================================================

ğŸ“¥ Loading model from checkpoints/best_model.pth
   Epoch: 45
   Best loss: 0.5432
âœ… Model loaded successfully

ğŸ“¦ Loading dataset...
âœ… Loaded 1000 images

ğŸ“Š Processing 50 samples...
Visualizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:23<00:00,  2.11it/s]

================================================================================
ğŸ“Š Statistics
================================================================================
Images processed: 50
Total detections: 127
Avg detections/image: 2.54
High confidence (>0.5): 98
Total ground truth: 132
Avg GT/image: 2.64
================================================================================

âœ… Visualizations saved to: visualizations
âœ… Detection crops saved to: visualizations/crops/
```

### å¯è§†åŒ–è¯´æ˜
- ğŸŸ¢ **ç»¿è‰²æ¡†**: Ground truthï¼ˆçœŸå®æ ‡æ³¨ï¼‰
- ğŸ”´ **çº¢è‰²æ¡†**: æ¨¡å‹é¢„æµ‹
- æ¯ä¸ªæ¡†æ˜¾ç¤ºï¼šç±»åˆ« + ç½®ä¿¡åº¦åˆ†æ•°

---

## â“ å¸¸è§é—®é¢˜

### Q1: æ˜¾å­˜ä¸è¶³ï¼ˆCUDA out of memoryï¼‰
```bash
# æ–¹æ¡ˆ1: å‡å°batch size
python train_enhanced.py --batch_size 4

# æ–¹æ¡ˆ2: å‡å°å›¾åƒå°ºå¯¸ï¼ˆéœ€ä¿®æ”¹configï¼‰
# åœ¨ config/sar_ship_config.py ä¸­:
IMG_SIZE = (384, 384)  # åŸæ¥æ˜¯ (512, 512)

# æ–¹æ¡ˆ3: ç¦ç”¨éƒ¨åˆ†å¢å¼ºæ¨¡å—
python train_enhanced.py --no_frequency  # æˆ– --no_attention
```

### Q2: æŸå¤±ä¸ºNaN
```bash
# æ–¹æ¡ˆ1: é™ä½å­¦ä¹ ç‡
# åœ¨ config/sar_ship_config.py ä¸­:
OPTIMIZER = {
    'lr': 5e-5,  # åŸæ¥æ˜¯ 1e-4
    ...
}

# æ–¹æ¡ˆ2: å¯ç”¨æ¢¯åº¦è£å‰ªï¼ˆå·²é»˜è®¤å¯ç”¨ï¼‰
GRAD_CLIP_MAX_NORM = 5.0  # åŸæ¥æ˜¯ 10.0

# æ–¹æ¡ˆ3: æ£€æŸ¥æ•°æ®
python test_model.py --test data
```

### Q3: è®­ç»ƒé€Ÿåº¦æ…¢
```bash
# æ–¹æ¡ˆ1: å‡å°‘æ•°æ®åŠ è½½workeræ•°
# åœ¨ config/sar_ship_config.py ä¸­:
NUM_WORKERS = 2  # åŸæ¥æ˜¯ 4

# æ–¹æ¡ˆ2: ç¦ç”¨æŸäº›å¢å¼ºæ¨¡å—
python train_enhanced.py --no_attention --no_frequency

# æ–¹æ¡ˆ3: ä½¿ç”¨baselineæ¨¡å‹
python train_enhanced.py --baseline
```

### Q4: æ¨¡å‹ä¸æ”¶æ•›
```bash
# æ–¹æ¡ˆ1: å¢åŠ warmup epochs
# åœ¨ config/sar_ship_config.py ä¸­:
WARMUP_EPOCHS = 10  # åŸæ¥æ˜¯ 5

# æ–¹æ¡ˆ2: è°ƒæ•´å­¦ä¹ ç‡ç­–ç•¥
SCHEDULER = {
    'type': 'StepLR',
    'step_size': 20,
    'gamma': 0.5
}

# æ–¹æ¡ˆ3: ç¦ç”¨å·®å¼‚åŒ–å­¦ä¹ ç‡
python train_enhanced.py --no_diff_lr
```

### Q5: å¦‚ä½•å¯¹æ¯”ä¸åŒé…ç½®ï¼Ÿ
```bash
# è®­ç»ƒbaseline
python train_enhanced.py --baseline --exp_name baseline

# è®­ç»ƒä»…ç”¨attention
python train_enhanced.py --no_frequency --exp_name only_attention

# è®­ç»ƒä»…ç”¨frequency
python train_enhanced.py --no_attention --exp_name only_frequency

# è®­ç»ƒå®Œæ•´ç‰ˆæœ¬
python train_enhanced.py --exp_name full_enhanced

# æŸ¥çœ‹æ‰€æœ‰å®éªŒç»“æœ
ls logs/  # æ¯ä¸ªå®éªŒæœ‰ç‹¬ç«‹ç›®å½•
```

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ•°æ®å¢å¼º
å¦‚æœè®­ç»ƒé›†è¾ƒå°ï¼Œå¯ä»¥åœ¨ `data/datasets.py` ä¸­å¯ç”¨æ›´å¤šå¢å¼ºï¼š
- éšæœºæ—‹è½¬
- éšæœºç¿»è½¬
- éšæœºäº®åº¦/å¯¹æ¯”åº¦è°ƒæ•´
- Mixup / CutMix

### 2. å­¦ä¹ ç‡è°ƒä¼˜
```python
# æ‰¾åˆ°æœ€ä½³å­¦ä¹ ç‡ - åœ¨ config/sar_ship_config.py
OPTIMIZER = {
    'type': 'AdamW',
    'lr': 1e-4,  # å¯å°è¯•: 5e-5, 1e-4, 5e-4
    'weight_decay': 1e-4,
}

# å·®å¼‚åŒ–å­¦ä¹ ç‡è°ƒä¼˜
DIFFERENTIAL_LR = {
    'enabled': True,
    'backbone_lr_mult': 0.1,     # Backboneç”¨è¾ƒå°å­¦ä¹ ç‡
    'attention_lr_mult': 1.0,    # æ–°æ¨¡å—ç”¨æ ‡å‡†å­¦ä¹ ç‡
    'frequency_lr_mult': 1.0,
    'neck_lr_mult': 1.0,
    'head_lr_mult': 1.0,
}
```

### 3. æŸå¤±å‡½æ•°æƒé‡è°ƒæ•´
```python
# åœ¨ config/sar_ship_config.py
LOSS = {
    'focal_loss': {
        'alpha': 0.25,      # æ­£è´Ÿæ ·æœ¬å¹³è¡¡
        'gamma': 2.0,       # éš¾æ˜“æ ·æœ¬æƒé‡
        'weight': 1.0
    },
    'ciou_loss': {
        'weight': 1.0       # å¯è°ƒæ•´ä¸º 0.5-2.0
    }
}
```

### 4. Anchoré…ç½®ä¼˜åŒ–
æ ¹æ®ä½ çš„æ•°æ®é›†ä¸­ç›®æ ‡çš„å°ºå¯¸åˆ†å¸ƒè°ƒæ•´ï¼š
```python
ANCHOR_GENERATOR = {
    'scales': [8, 16, 32],      # æ ¹æ®ç›®æ ‡å¤§å°è°ƒæ•´
    'ratios': [0.5, 1.0, 2.0],  # æ ¹æ®ç›®æ ‡é•¿å®½æ¯”è°ƒæ•´
    'strides': [8, 16, 32]
}
```

---

## ğŸ”¬ é«˜çº§ç”¨æ³•

### 1. è‡ªå®šä¹‰æ¨¡å‹é…ç½®

åˆ›å»ºè‡ªå·±çš„é…ç½®ç±»ï¼š
```python
# my_config.py
from config.sar_ship_config import SARShipConfig

class MyConfig(SARShipConfig):
    # è¦†ç›–éœ€è¦ä¿®æ”¹çš„å‚æ•°
    BATCH_SIZE = 16
    EPOCHS = 150
    IMG_SIZE = (640, 640)
    
    ATTENTION_CONFIG = {
        'use_attention': True,
        'cbam_reduction': 8,  # æ›´å¼ºçš„æ³¨æ„åŠ›
        ...
    }

cfg = MyConfig()
```

### 2. æ¨¡å—æ¶ˆèå®éªŒ

åˆ›å»ºå®éªŒè„šæœ¬ï¼š
```bash
#!/bin/bash
# ablation_study.sh

# Baseline
python train_enhanced.py --baseline --exp_name exp_baseline --epochs 50

# Only Attention
python train_enhanced.py --no_frequency --exp_name exp_attention --epochs 50

# Only Frequency
python train_enhanced.py --no_attention --exp_name exp_frequency --epochs 50

# Attention + Frequency (No Diff LR)
python train_enhanced.py --no_diff_lr --exp_name exp_both_nodiff --epochs 50

# Full (Attention + Frequency + Diff LR)
python train_enhanced.py --exp_name exp_full --epochs 50
```

è¿è¡Œï¼š
```bash
chmod +x ablation_study.sh
./ablation_study.sh
```

### 3. å¤šGPUè®­ç»ƒ

ä¿®æ”¹ `train_enhanced.py`:
```python
# åœ¨main()å‡½æ•°ä¸­æ·»åŠ 
if torch.cuda.device_count() > 1:
    print(f"Using {torch.cuda.device_count()} GPUs!")
    model = torch.nn.DataParallel(model)
```

### 4. æ··åˆç²¾åº¦è®­ç»ƒç›‘æ§

æŸ¥çœ‹AMPæ˜¯å¦æ­£å¸¸å·¥ä½œï¼š
```python
# åœ¨ engine/trainer.py çš„ train_epoch ä¸­æ·»åŠ 
if self.use_amp and batch_idx % 100 == 0:
    print(f"Scaler scale: {self.scaler.get_scale():.2f}")
```

---

## ğŸ“ å®éªŒè®°å½•æ¨¡æ¿

### å®éªŒé…ç½®è¡¨æ ¼
| å®éªŒåç§° | Attention | Frequency | Diff LR | Batch Size | Epochs | Best mAP |
|---------|-----------|-----------|---------|------------|--------|----------|
| baseline | âŒ | âŒ | âŒ | 8 | 50 | 0.XXX |
| att_only | âœ… | âŒ | âŒ | 8 | 50 | 0.XXX |
| freq_only | âŒ | âœ… | âŒ | 8 | 50 | 0.XXX |
| full | âœ… | âœ… | âœ… | 8 | 50 | 0.XXX |

### è®­ç»ƒæ—¥å¿—åˆ†æ

æ£€æŸ¥è®­ç»ƒæ›²çº¿ï¼š
```bash
# æŸ¥çœ‹æ‰€æœ‰å®éªŒçš„æ›²çº¿
ls logs/*/curves/training_curves.png

# ä½¿ç”¨å›¾åƒæŸ¥çœ‹å™¨å¯¹æ¯”
eog logs/*/curves/training_curves.png  # Linux
open logs/*/curves/training_curves.png  # Mac
```

---

## ğŸ› è°ƒè¯•æŠ€å·§

### 1. å¯ç”¨å¼‚å¸¸æ£€æµ‹
```python
# åœ¨ config/sar_ship_config.py
DEBUG = {
    'detect_anomaly': True,  # æ£€æµ‹NaN/Inf
    'print_model': True      # æ‰“å°æ¨¡å‹ç»“æ„
}
```

### 2. æ‰“å°æ¨¡å‹ç»“æ„
```python
# åœ¨è®­ç»ƒå‰æ·»åŠ 
from