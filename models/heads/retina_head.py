import torch
import torch.nn as nn
import math
import torch.nn.functional as F

class RetinaHead(nn.Module):
    """RetinaNet Detection Head with proper initialization (æ·»åŠ  target_size æ”¯æŒ)"""
    
    # 1. åœ¨ __init__ æ–¹æ³•å‚æ•°åˆ—è¡¨ä¸­æ–°å¢ target_sizeï¼Œæ”¾åœ¨**kwargs å‰
    def __init__(self, in_channels, num_anchors, num_classes=1, target_size=None, **kwargs):
        super().__init__()
        
        if kwargs:
            print(f"ğŸ” RetinaHead ignored kwargs: {list(kwargs.keys())}")
        
        self.num_anchors = num_anchors
        self.num_classes = num_classes
        # 2. ä¿å­˜ target_size ä¸ºå®ä¾‹å±æ€§ï¼ˆä¾›åç»­å°ºå¯¸ç›¸å…³è®¡ç®—ä½¿ç”¨ï¼‰
        self.target_size = target_size  # æ ¼å¼ä¸º (H, W)ï¼Œå¦‚ (512, 512)
        # è‹¥æœªä¼ å…¥ target_sizeï¼Œé»˜è®¤ç”¨ 512x512ï¼ˆé¿å…åç»­è®¡ç®—æŠ¥é”™ï¼‰
        if self.target_size is None:
            self.target_size = (512, 512)
            print(f"âš ï¸ RetinaHead: target_size not provided, using default (512, 512)")
        
        # Classification subnet (4å±‚å·ç§¯)
        cls_layers = []
        for _ in range(4):
            cls_layers.extend([
                nn.Conv2d(in_channels, in_channels, 3, padding=1, bias=True),
                nn.ReLU(inplace=True)
            ])
        self.cls_subnet = nn.Sequential(*cls_layers)
        self.cls_score = nn.Conv2d(
            in_channels, num_anchors * num_classes, 3, padding=1, bias=True
        )
        
        # Regression subnet (4å±‚å·ç§¯)
        reg_layers = []
        for _ in range(4):
            reg_layers.extend([
                nn.Conv2d(in_channels, in_channels, 3, padding=1, bias=True),
                nn.ReLU(inplace=True)
            ])
        self.reg_subnet = nn.Sequential(*reg_layers)
        self.bbox_pred = nn.Conv2d(
            in_channels, num_anchors * 4, 3, padding=1, bias=True
        )
        
        # ğŸ”¥ å…³é”®ä¿®å¤2: åˆå§‹åŒ–æƒé‡
        self._init_weights()
        
        # 3. æ‰“å°æ—¥å¿—æ—¶å¢åŠ  target_size ä¿¡æ¯ï¼Œæ–¹ä¾¿è°ƒè¯•
        print(f"âœ… RetinaHead initialized: anchors={num_anchors}, classes={num_classes}, target_size={self.target_size}")
    
    def _init_weights(self):
        """Initialize weights for numerical stability"""
        # åˆ†ç±»å­ç½‘ç»œåˆå§‹åŒ–
        for module in self.cls_subnet.modules():
            if isinstance(module, nn.Conv2d):
                nn.init.normal_(module.weight, std=0.01)
                nn.init.constant_(module.bias, 0)
        
        # ğŸ”¥ å…³é”®ä¿®å¤3: åˆ†ç±»è¾“å‡ºå±‚ç‰¹æ®Šåˆå§‹åŒ–
        # ä½¿ç”¨prior probabilityåˆå§‹åŒ–åç½®ï¼Œè¿™æ˜¯é˜²æ­¢NaNçš„å…³é”®ï¼
        prior_prob = 0.01
        bias_value = -math.log((1 - prior_prob) / prior_prob)
        nn.init.normal_(self.cls_score.weight, std=0.01)
        nn.init.constant_(self.cls_score.bias, bias_value)
        
        # å›å½’å­ç½‘ç»œåˆå§‹åŒ–
        for module in self.reg_subnet.modules():
            if isinstance(module, nn.Conv2d):
                nn.init.normal_(module.weight, std=0.01)
                nn.init.constant_(module.bias, 0)
        
        nn.init.normal_(self.bbox_pred.weight, std=0.01)
        nn.init.constant_(self.bbox_pred.bias, 0)
    
    def forward(self, feats):
        """Forward pass (å¯åŸºäº self.target_size æ‰©å±•å°ºå¯¸ç›¸å…³é€»è¾‘)"""
        cls_scores = []
        bbox_preds = []
        
        for feat in feats:
            # åˆ†ç±»åˆ†æ”¯
            cls_feat = self.cls_subnet(feat)
            cls_score = self.cls_score(cls_feat)
            cls_scores.append(cls_score)
            
            # å›å½’åˆ†æ”¯
            reg_feat = self.reg_subnet(feat)
            bbox_pred = self.bbox_pred(reg_feat)
            bbox_preds.append(bbox_pred)
        
        # ï¼ˆå¯é€‰ï¼‰è‹¥åç»­éœ€è¦å°†é¢„æµ‹æ¡†åæ ‡æ˜ å°„å›åŸå›¾å°ºå¯¸ï¼Œå¯åŸºäº self.target_size è®¡ç®—
        # ç¤ºä¾‹ï¼šbbox_preds = self._map_bbox_to_original_size(bbox_preds)
        
        return cls_scores, bbox_preds