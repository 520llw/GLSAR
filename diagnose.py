"""
6ç±»åˆ«é…ç½®å®Œæ•´éªŒè¯è„šæœ¬
è¿è¡Œæ­¤è„šæœ¬æ£€æŸ¥æ‰€æœ‰é…ç½®æ˜¯å¦æ­£ç¡®ï¼Œæ˜¯å¦å¯ä»¥å¼€å§‹è®­ç»ƒ
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

import torch
import traceback


def print_section(title):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print("\n" + "="*80)
    print(f"  {title}")
    print("="*80)


def check_config():
    """æ£€æŸ¥é…ç½®æ–‡ä»¶"""
    print_section("1ï¸âƒ£ æ£€æŸ¥é…ç½®æ–‡ä»¶")
    
    errors = []
    warnings = []
    
    try:
        from config.sar_ship_config import cfg
        print("âœ… é…ç½®æ–‡ä»¶å¯¼å…¥æˆåŠŸ")
        
        # æ£€æŸ¥ç±»åˆ«å®šä¹‰
        print(f"\nğŸ“‹ ç±»åˆ«é…ç½®:")
        print(f"   CLASSES = {cfg.CLASSES}")
        print(f"   NUM_CLASSES = {cfg.NUM_CLASSES if hasattr(cfg, 'NUM_CLASSES') else 'NOT DEFINED'}")
        
        if len(cfg.CLASSES) != 6:
            errors.append(f"âŒ cfg.CLASSES åº”è¯¥æœ‰6ä¸ªå…ƒç´ ï¼Œå®é™…: {len(cfg.CLASSES)}")
        else:
            print(f"   âœ… ç±»åˆ«æ•°é‡æ­£ç¡®: {len(cfg.CLASSES)}")
        
        expected_classes = ['cargo', 'tanker', 'container', 'fishing', 'passenger', 'military']
        if cfg.CLASSES != expected_classes:
            warnings.append(f"âš ï¸  ç±»åˆ«åç§°ä¸é¢„æœŸä¸åŒ")
            print(f"   é¢„æœŸ: {expected_classes}")
            print(f"   å®é™…: {cfg.CLASSES}")
        
        # æ£€æŸ¥HEADé…ç½®
        print(f"\nğŸ“‹ HEADé…ç½®:")
        print(f"   num_classes = {cfg.HEAD.get('num_classes', 'NOT DEFINED')}")
        
        if cfg.HEAD.get('num_classes', 1) != 6:
            errors.append(f"âŒ cfg.HEAD['num_classes'] åº”è¯¥æ˜¯6ï¼Œå®é™…: {cfg.HEAD.get('num_classes')}")
        else:
            print(f"   âœ… HEAD num_classes æ­£ç¡®: 6")
        
        # æ£€æŸ¥ç±»åˆ«é¢œè‰²
        if hasattr(cfg, 'CLASS_COLORS'):
            print(f"\nğŸ“‹ ç±»åˆ«é¢œè‰²:")
            if len(cfg.CLASS_COLORS) == 6:
                print(f"   âœ… å·²é…ç½® {len(cfg.CLASS_COLORS)} ç§é¢œè‰²")
                for cls, color in cfg.CLASS_COLORS.items():
                    print(f"      {cls:<12} {color}")
            else:
                warnings.append(f"âš ï¸  CLASS_COLORS åº”è¯¥æœ‰6ç§é¢œè‰²ï¼Œå®é™…: {len(cfg.CLASS_COLORS)}")
        else:
            warnings.append("âš ï¸  æœªå®šä¹‰ CLASS_COLORSï¼ˆå»ºè®®æ·»åŠ ï¼‰")
        
        # æ£€æŸ¥è®­ç»ƒå‚æ•°
        print(f"\nğŸ“‹ è®­ç»ƒå‚æ•°:")
        print(f"   EPOCHS = {cfg.EPOCHS}")
        print(f"   BATCH_SIZE = {cfg.BATCH_SIZE}")
        print(f"   Learning Rate = {cfg.OPTIMIZER['lr']:.2e}")
        print(f"   WARMUP_EPOCHS = {cfg.WARMUP_EPOCHS}")
        
        if cfg.EPOCHS < 100:
            warnings.append(f"âš ï¸  6ç±»åˆ«å»ºè®®è®­ç»ƒè‡³å°‘100 epochsï¼Œå½“å‰: {cfg.EPOCHS}")
        
        return errors, warnings
        
    except Exception as e:
        errors.append(f"âŒ é…ç½®æ–‡ä»¶é”™è¯¯: {str(e)}")
        traceback.print_exc()
        return errors, warnings


def check_model():
    """æ£€æŸ¥æ¨¡å‹åˆå§‹åŒ–"""
    print_section("2ï¸âƒ£ æ£€æŸ¥æ¨¡å‹åˆå§‹åŒ–")
    
    errors = []
    
    try:
        from models.detectors.denodet_enhanced import EnhancedDenoDet
        from config.sar_ship_config import cfg
        
        print("æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")
        model = EnhancedDenoDet(use_attention=True, use_frequency=True)
        print("âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
        
        # æ£€æŸ¥æ¨¡å‹å‚æ•°
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"\nğŸ“Š æ¨¡å‹å‚æ•°:")
        print(f"   æ€»å‚æ•°é‡: {total_params:,}")
        print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        print(f"   æ¨¡å‹å¤§å°: ~{total_params * 4 / 1024 / 1024:.1f} MB")
        
        # æ£€æŸ¥Headçš„ç±»åˆ«æ•°
        if hasattr(model, 'head') and hasattr(model.head, 'num_classes'):
            head_classes = model.head.num_classes
            print(f"\nğŸ“‹ Headé…ç½®:")
            print(f"   num_classes = {head_classes}")
            
            if head_classes != 6:
                errors.append(f"âŒ model.head.num_classes åº”è¯¥æ˜¯6ï¼Œå®é™…: {head_classes}")
            else:
                print(f"   âœ… Headç±»åˆ«æ•°æ­£ç¡®: 6")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        print(f"\nğŸ§ª æµ‹è¯•å‰å‘ä¼ æ’­...")
        model.eval()
        with torch.no_grad():
            # åˆ›å»ºå‡æ•°æ®
            dummy_img = torch.randn(1, 1, 512, 512)
            dummy_inputs = {'img': dummy_img}
            
            try:
                results = model(dummy_inputs, mode='test')
                print(f"   âœ… æ¨ç†æ¨¡å¼æˆåŠŸ")
                print(f"   è¾“å‡ºæ ¼å¼: {results[0].keys()}")
                
                # æ£€æŸ¥è¾“å‡º
                labels = results[0]['labels']
                if len(labels) > 0:
                    max_label = labels.max().item()
                    if max_label >= 6:
                        errors.append(f"âŒ è¾“å‡ºçš„labelè¶…å‡ºèŒƒå›´ (0-5): {max_label}")
                    else:
                        print(f"   âœ… æ ‡ç­¾èŒƒå›´æ­£ç¡®: 0-{max_label}")
                
            except Exception as e:
                errors.append(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {str(e)}")
                traceback.print_exc()
        
        return errors
        
    except Exception as e:
        errors.append(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        traceback.print_exc()
        return errors


def check_data():
    """æ£€æŸ¥æ•°æ®åŠ è½½"""
    print_section("3ï¸âƒ£ æ£€æŸ¥æ•°æ®åŠ è½½")
    
    errors = []
    warnings = []
    
    try:
        from data.loaders import get_train_dataloader
        from config.sar_ship_config import cfg
        
        print("æ­£åœ¨åŠ è½½è®­ç»ƒæ•°æ®...")
        
        # æ£€æŸ¥æ•°æ®è·¯å¾„
        print(f"\nğŸ“ æ•°æ®è·¯å¾„:")
        print(f"   è®­ç»ƒå›¾åƒ: {cfg.TRAIN_IMG_DIR}")
        print(f"   è®­ç»ƒæ ‡ç­¾: {cfg.TRAIN_LABEL_DIR}")
        
        if not cfg.TRAIN_IMG_DIR.exists():
            errors.append(f"âŒ è®­ç»ƒå›¾åƒç›®å½•ä¸å­˜åœ¨: {cfg.TRAIN_IMG_DIR}")
            return errors, warnings
        
        if not cfg.TRAIN_LABEL_DIR.exists():
            errors.append(f"âŒ è®­ç»ƒæ ‡ç­¾ç›®å½•ä¸å­˜åœ¨: {cfg.TRAIN_LABEL_DIR}")
            return errors, warnings
        
        # ç»Ÿè®¡æ–‡ä»¶æ•°é‡
        num_images = len(list(cfg.TRAIN_IMG_DIR.glob('*.jpg'))) + \
                    len(list(cfg.TRAIN_IMG_DIR.glob('*.png')))
        num_labels = len(list(cfg.TRAIN_LABEL_DIR.glob('*.txt')))
        
        print(f"   å›¾åƒæ•°é‡: {num_images}")
        print(f"   æ ‡ç­¾æ•°é‡: {num_labels}")
        
        if num_images == 0:
            errors.append(f"âŒ æœªæ‰¾åˆ°è®­ç»ƒå›¾åƒ")
            return errors, warnings
        
        if num_labels == 0:
            errors.append(f"âŒ æœªæ‰¾åˆ°è®­ç»ƒæ ‡ç­¾")
            return errors, warnings
        
        if abs(num_images - num_labels) > 0:
            warnings.append(f"âš ï¸  å›¾åƒå’Œæ ‡ç­¾æ•°é‡ä¸åŒ¹é…: {num_images} vs {num_labels}")
        
        # åŠ è½½ä¸€ä¸ªbatch
        print(f"\nğŸ§ª æµ‹è¯•æ•°æ®åŠ è½½...")
        loader = get_train_dataloader()
        print(f"   âœ… DataLoaderåˆ›å»ºæˆåŠŸ")
        print(f"   Batchæ•°é‡: {len(loader)}")
        
        try:
            batch = next(iter(loader))
            print(f"   âœ… æˆåŠŸåŠ è½½ä¸€ä¸ªbatch")
            
            # æ£€æŸ¥batchå†…å®¹
            print(f"\nğŸ“¦ Batchå†…å®¹:")
            print(f"   å›¾åƒshape: {batch['img'].shape}")
            print(f"   GT boxesæ•°é‡: {[len(b) for b in batch['gt_bboxes'][:3]]}")
            print(f"   GT labelsæ•°é‡: {[len(l) for l in batch['gt_labels'][:3]]}")
            
            # æ£€æŸ¥æ ‡ç­¾èŒƒå›´
            all_labels = torch.cat(batch['gt_labels'])
            if len(all_labels) > 0:
                min_label = all_labels.min().item()
                max_label = all_labels.max().item()
                print(f"\nğŸ“‹ æ ‡ç­¾ç»Ÿè®¡:")
                print(f"   æ ‡ç­¾èŒƒå›´: {min_label} - {max_label}")
                
                if min_label < 0 or max_label > 5:
                    errors.append(f"âŒ æ ‡ç­¾è¶…å‡ºèŒƒå›´ (åº”è¯¥æ˜¯0-5): {min_label}-{max_label}")
                else:
                    print(f"   âœ… æ ‡ç­¾èŒƒå›´æ­£ç¡® (0-5)")
                
                # ç»Ÿè®¡å„ç±»åˆ«æ•°é‡
                print(f"\nğŸ“Š ç±»åˆ«åˆ†å¸ƒ:")
                for i in range(6):
                    count = (all_labels == i).sum().item()
                    if count > 0:
                        class_name = cfg.CLASSES[i]
                        print(f"   {i}: {class_name:<12} {count:>3} ä¸ª")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æœªä½¿ç”¨çš„ç±»åˆ«
                used_classes = set(all_labels.unique().cpu().numpy())
                for i in range(6):
                    if i not in used_classes:
                        warnings.append(f"âš ï¸  ç±»åˆ« {i} ({cfg.CLASSES[i]}) åœ¨æ­¤batchä¸­æœªå‡ºç°")
            
        except Exception as e:
            errors.append(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
            traceback.print_exc()
        
        return errors, warnings
        
    except Exception as e:
        errors.append(f"âŒ æ•°æ®æ£€æŸ¥å¤±è´¥: {str(e)}")
        traceback.print_exc()
        return errors, warnings


def check_optimizer():
    """æ£€æŸ¥ä¼˜åŒ–å™¨"""
    print_section("4ï¸âƒ£ æ£€æŸ¥ä¼˜åŒ–å™¨")
    
    errors = []
    
    try:
        from models.detectors.denodet_enhanced import EnhancedDenoDet
        from config.sar_ship_config import cfg
        
        model = EnhancedDenoDet(use_attention=False, use_frequency=False)
        
        # æ ‡å‡†ä¼˜åŒ–å™¨
        print("ğŸ”§ æ ‡å‡†ä¼˜åŒ–å™¨:")
        opt_std = cfg.get_optimizer(model)
        print(f"   ç±»å‹: {type(opt_std).__name__}")
        print(f"   å‚æ•°ç»„æ•°: {len(opt_std.param_groups)}")
        print(f"   å­¦ä¹ ç‡: {opt_std.param_groups[0]['lr']:.2e}")
        
        # å¢å¼ºä¼˜åŒ–å™¨
        print(f"\nğŸ”§ å¢å¼ºä¼˜åŒ–å™¨ (å·®å¼‚åŒ–å­¦ä¹ ç‡):")
        model_enh = EnhancedDenoDet(use_attention=True, use_frequency=True)
        opt_enh = cfg.get_optimizer_enhanced(model_enh)
        print(f"   ç±»å‹: {type(opt_enh).__name__}")
        print(f"   å‚æ•°ç»„æ•°: {len(opt_enh.param_groups)}")
        
        for i, group in enumerate(opt_enh.param_groups):
            num_params = sum(p.numel() for p in group['params'])
            print(f"   ç»„{i}: {num_params:>10,} å‚æ•°, lr={group['lr']:.2e}")
        
        print(f"   âœ… ä¼˜åŒ–å™¨åˆ›å»ºæˆåŠŸ")
        
        return errors
        
    except Exception as e:
        errors.append(f"âŒ ä¼˜åŒ–å™¨æ£€æŸ¥å¤±è´¥: {str(e)}")
        traceback.print_exc()
        return errors


def check_training():
    """æ£€æŸ¥è®­ç»ƒæµç¨‹"""
    print_section("5ï¸âƒ£ æ£€æŸ¥è®­ç»ƒæµç¨‹")
    
    errors = []
    
    try:
        from models.detectors.denodet_enhanced import EnhancedDenoDet
        from data.loaders import get_train_dataloader
        from config.sar_ship_config import cfg
        
        print("ğŸ”§ åˆ›å»ºæ¨¡å‹...")
        model = EnhancedDenoDet(use_attention=True, use_frequency=True)
        device = cfg.DEVICE
        model = model.to(device)
        
        print("ğŸ“¦ åŠ è½½æ•°æ®...")
        loader = get_train_dataloader()
        batch = next(iter(loader))
        
        print("ğŸ§ª æµ‹è¯•è®­ç»ƒæ¨¡å¼...")
        model.train()
        
        imgs = batch['img'].to(device)
        gt_bboxes = [bbox.to(device) for bbox in batch['gt_bboxes']]
        gt_labels = [label.to(device) for label in batch['gt_labels']]
        
        inputs = {
            'img': imgs,
            'gt_bboxes': gt_bboxes,
            'gt_labels': gt_labels
        }
        
        try:
            outputs = model(inputs, mode='train')
            print(f"   âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
            print(f"   Total loss: {outputs['total_loss'].item():.4f}")
            print(f"   Cls loss: {outputs['cls_loss'].item():.4f}")
            print(f"   Bbox loss: {outputs['bbox_loss'].item():.4f}")
            
            # æµ‹è¯•åå‘ä¼ æ’­
            print(f"\nğŸ”™ æµ‹è¯•åå‘ä¼ æ’­...")
            outputs['total_loss'].backward()
            print(f"   âœ… åå‘ä¼ æ’­æˆåŠŸ")
            
            # æ£€æŸ¥æ¢¯åº¦
            has_grad = False
            nan_grad = False
            for name, param in model.named_parameters():
                if param.grad is not None:
                    has_grad = True
                    if torch.isnan(param.grad).any():
                        nan_grad = True
                        break
            
            if not has_grad:
                errors.append("âŒ æ²¡æœ‰è®¡ç®—æ¢¯åº¦")
            elif nan_grad:
                errors.append("âŒ æ¢¯åº¦åŒ…å«NaN")
            else:
                print(f"   âœ… æ¢¯åº¦æ­£å¸¸")
            
        except Exception as e:
            errors.append(f"âŒ è®­ç»ƒæµç¨‹å¤±è´¥: {str(e)}")
            traceback.print_exc()
        
        return errors
        
    except Exception as e:
        errors.append(f"âŒ è®­ç»ƒæ£€æŸ¥å¤±è´¥: {str(e)}")
        traceback.print_exc()
        return errors


def print_summary(all_errors, all_warnings):
    """æ‰“å°æ€»ç»“"""
    print_section("ğŸ“Š éªŒè¯æ€»ç»“")
    
    # æ‰“å°è­¦å‘Š
    if all_warnings:
        print(f"\nâš ï¸  è­¦å‘Š ({len(all_warnings)} ä¸ª):")
        for warning in all_warnings:
            print(f"   {warning}")
    
    # æ‰“å°é”™è¯¯
    if all_errors:
        print(f"\nâŒ é”™è¯¯ ({len(all_errors)} ä¸ª):")
        for error in all_errors:
            print(f"   {error}")
        
        print("\n" + "="*80)
        print("âŒ éªŒè¯å¤±è´¥ï¼è¯·ä¿®å¤ä¸Šè¿°é”™è¯¯åå†è®­ç»ƒã€‚")
        print("="*80)
        return False
    else:
        if all_warnings:
            print("\n" + "="*80)
            print("âš ï¸  éªŒè¯é€šè¿‡ï¼Œä½†æœ‰ä¸€äº›è­¦å‘Šå»ºè®®å¤„ç†ã€‚")
            print("å¯ä»¥å¼€å§‹è®­ç»ƒï¼Œä½†å»ºè®®å…ˆæŸ¥çœ‹è­¦å‘Šä¿¡æ¯ã€‚")
            print("="*80)
        else:
            print("\n" + "="*80)
            print("âœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼å¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼")
            print("="*80)
            print("\nğŸš€ å¼€å§‹è®­ç»ƒå‘½ä»¤:")
            print("   python train_enhanced.py --batch_size 4 --epochs 120 --exp_name my_6class")
            print("\næˆ–ä½¿ç”¨baselineæ¨¡å¼ï¼ˆæ›´å¿«ï¼‰:")
            print("   python train_enhanced.py --baseline --batch_size 8 --epochs 100")
            print("="*80)
        return True


def main():
    """ä¸»å‡½æ•°"""
    print("="*80)
    print("ğŸ” SARèˆ°èˆ¹æ£€æµ‹ - 6ç±»åˆ«é…ç½®éªŒè¯")
    print("="*80)
    print("æ­¤è„šæœ¬å°†æ£€æŸ¥æ‰€æœ‰é…ç½®æ˜¯å¦æ­£ç¡®ï¼Œç¡®ä¿å¯ä»¥å¼€å§‹è®­ç»ƒ")
    print("="*80)
    
    all_errors = []
    all_warnings = []
    
    # 1. æ£€æŸ¥é…ç½®
    errors, warnings = check_config()
    all_errors.extend(errors)
    all_warnings.extend(warnings)
    
    if errors:
        print("\nâŒ é…ç½®æ–‡ä»¶æœ‰é”™è¯¯ï¼Œæ— æ³•ç»§ç»­æ£€æŸ¥")
        print_summary(all_errors, all_warnings)
        return False
    
    # 2. æ£€æŸ¥æ¨¡å‹
    errors = check_model()
    all_errors.extend(errors)
    
    if errors:
        print("\nâŒ æ¨¡å‹åˆå§‹åŒ–æœ‰é”™è¯¯ï¼Œæ— æ³•ç»§ç»­æ£€æŸ¥")
        print_summary(all_errors, all_warnings)
        return False
    
    # 3. æ£€æŸ¥æ•°æ®
    errors, warnings = check_data()
    all_errors.extend(errors)
    all_warnings.extend(warnings)
    
    if errors:
        print("\nâŒ æ•°æ®åŠ è½½æœ‰é”™è¯¯ï¼Œæ— æ³•ç»§ç»­æ£€æŸ¥")
        print_summary(all_errors, all_warnings)
        return False
    
    # 4. æ£€æŸ¥ä¼˜åŒ–å™¨
    errors = check_optimizer()
    all_errors.extend(errors)
    
    # 5. æ£€æŸ¥è®­ç»ƒæµç¨‹
    errors = check_training()
    all_errors.extend(errors)
    
    # æ‰“å°æ€»ç»“
    success = print_summary(all_errors, all_warnings)
    
    return success


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)